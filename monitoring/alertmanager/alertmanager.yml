global:
  # Global configuration
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@secondopinion.com'
  smtp_auth_username: 'alerts@secondopinion.com'
  smtp_auth_password: 'smtp-password'
  smtp_require_tls: true
  
  # Slack configuration
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
  
  # PagerDuty configuration
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'
  
  # OpsGenie configuration
  opsgenie_api_url: 'https://api.opsgenie.com/v2/alerts'
  
  # Default resolve timeout
  resolve_timeout: 5m

# Template files for custom notification formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route configuration
route:
  # Default receiver for unmatched alerts
  receiver: 'default-receiver'
  
  # How long to wait before sending a notification
  group_wait: 10s
  
  # How long to wait before sending notification about new alerts added to group
  group_interval: 10s
  
  # How long to wait before re-sending notification about same group
  repeat_interval: 1h
  
  # Group alerts by these labels
  group_by: ['alertname', 'cluster', 'service']
  
  # Child routes for specific alert handling
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 30m
      routes:
        # Service down alerts to on-call team
        - match:
            alertname: ServiceDown
          receiver: 'oncall-team'
          group_wait: 0s
          repeat_interval: 15m
        
        # Database issues to infrastructure team
        - match_re:
            alertname: (DatabaseConnectionFailure|CriticalDiskUsage)
          receiver: 'infrastructure-team'
    
    # Warning alerts - standard notification
    - match:
        severity: warning
      receiver: 'warning-alerts'
      repeat_interval: 2h
      routes:
        # High error rates to development team
        - match:
            alertname: HighErrorRate
          receiver: 'development-team'
        
        # Resource usage alerts to infrastructure team
        - match_re:
            alertname: (HighMemoryUsage|HighCPUUsage|HighDiskUsage)
          receiver: 'infrastructure-team'
        
        # Security related alerts
        - match_re:
            alertname: (IdentityServiceAuthFailures|APIGatewayRateLimitHit)
          receiver: 'security-team'
    
    # Business metrics alerts
    - match:
        service: business-metrics
      receiver: 'business-team'
      repeat_interval: 4h
    
    # Maintenance window - suppress alerts
    - match:
        maintenance: 'true'
      receiver: 'null'

# Inhibit rules to prevent alert spam
inhibit_rules:
  # Suppress warning alerts when critical alerts are firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']
  
  # Suppress individual service alerts when entire node is down
  - source_match:
      alertname: 'NodeDown'
    target_match_re:
      alertname: '(ServiceDown|HighLatency|HighErrorRate)'
    equal: ['instance']
  
  # Suppress high latency alerts when service is down
  - source_match:
      alertname: 'ServiceDown'
    target_match:
      alertname: 'HighLatency'
    equal: ['service']

# Notification receivers
receivers:
  # Default receiver - log to console
  - name: 'default-receiver'
    webhook_configs:
      - url: 'http://localhost:9093/api/v1/alerts'
        send_resolved: true

  # Null receiver for suppressed alerts
  - name: 'null'

  # Critical alerts - multiple channels
  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@secondopinion.com'
        subject: 'üö® CRITICAL: {{ .GroupLabels.alertname }} - {{ .GroupLabels.service }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Severity: {{ .Labels.severity }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          {{ if .Annotations.runbook_url }}
          Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
          {{ end }}
        headers:
          Subject: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - api_url: '{{ .slack_api_url }}'
        channel: '#alerts-critical'
        title: 'üö® Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Service:* {{ .Labels.service }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        color: 'danger'
    
    pagerduty_configs:
      - routing_key: 'YOUR_PAGERDUTY_ROUTING_KEY'
        description: '{{ .GroupLabels.alertname }} - {{ .GroupLabels.service }}'
        severity: 'critical'
        source: 'Prometheus'
        client: 'Second Opinion Platform'
        client_url: 'https://grafana.secondopinion.com'

  # On-call team for service outages
  - name: 'oncall-team'
    email_configs:
      - to: 'oncall@secondopinion.com'
        subject: 'üî• SERVICE DOWN: {{ .GroupLabels.service }}'
        body: |
          SERVICE OUTAGE DETECTED
          
          {{ range .Alerts }}
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          Description: {{ .Annotations.description }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          {{ end }}
          
          Please investigate immediately.
    
    slack_configs:
      - channel: '#oncall'
        title: 'üî• SERVICE DOWN: {{ .GroupLabels.service }}'
        text: 'Service {{ .GroupLabels.service }} is down. Immediate attention required!'
        color: 'danger'
    
    # SMS notification for critical outages
    webhook_configs:
      - url: 'https://api.twilio.com/2010-04-01/Accounts/YOUR_ACCOUNT_SID/Messages.json'
        http_config:
          basic_auth:
            username: 'YOUR_ACCOUNT_SID'
            password: 'YOUR_AUTH_TOKEN'

  # Warning alerts
  - name: 'warning-alerts'
    email_configs:
      - to: 'alerts@secondopinion.com'
        subject: '‚ö†Ô∏è  Warning: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          {{ end }}
    
    slack_configs:
      - channel: '#alerts-warning'
        title: '‚ö†Ô∏è  {{ .GroupLabels.alertname }}'
        color: 'warning'

  # Development team
  - name: 'development-team'
    email_configs:
      - to: 'dev-team@secondopinion.com'
        subject: 'üêõ Application Issue: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#dev-alerts'
        title: 'üêõ {{ .GroupLabels.alertname }}'

  # Infrastructure team
  - name: 'infrastructure-team'
    email_configs:
      - to: 'infra-team@secondopinion.com'
        subject: 'üñ•Ô∏è  Infrastructure Alert: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#infra-alerts'
        title: 'üñ•Ô∏è  {{ .GroupLabels.alertname }}'

  # Security team
  - name: 'security-team'
    email_configs:
      - to: 'security-team@secondopinion.com'
        subject: 'üîí Security Alert: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#security-alerts'
        title: 'üîí {{ .GroupLabels.alertname }}'
        color: 'danger'

  # Business team
  - name: 'business-team'
    email_configs:
      - to: 'business-team@secondopinion.com'
        subject: 'üìä Business Metrics Alert: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#business-metrics'
        title: 'üìä {{ .GroupLabels.alertname }}'